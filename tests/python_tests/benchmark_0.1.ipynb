{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Considerations for Fair Comparison\n",
    "\n",
    "In our project, the goal is to compare the performance of our Eigen-based wrappers (MyPyEigen) with NumPy's native operations. To ensure a fair, \"apple-to-apple\" comparison, we must minimize any extraneous overhead—particularly the Python binding overhead.\n",
    "\n",
    "## Key Points:\n",
    "\n",
    "1. **Minimizing Python Binding Overhead:**\n",
    "   - **Pre-Conversion:** When measuring the core computation, it is ideal to pre-convert NumPy arrays to Eigen objects (using our \"raw\" interfaces) so that the conversion cost is not included in the timing.\n",
    "   - **Batch Execution:** Repeating the function call many times and taking an average helps to dilute the fixed cost of the Python-to-C++ function call.\n",
    "   - **Optimized Binding Library:** We use pybind11, which is designed to be lightweight and to add minimal overhead compared to the actual C++ computation.\n",
    "\n",
    "2. **Excluding Non-Computational Overheads:**\n",
    "   - **Import Time:** Module import time is excluded from the benchmarks.\n",
    "   - **Data Preparation:** The time taken to generate test arrays is not included in the benchmark; only the computation is timed.\n",
    "   - **Cache Warm-Up:** We preheat the function (by calling it several times before measurement) to ensure that any cache initialization or one-time overhead does not skew the results.\n",
    "\n",
    "3. **Reproducibility and Consistency:**\n",
    "   - **Fixed Random Seed:** We set a fixed random seed (`np.random.seed(12345)`) so that the generated test arrays are consistent across runs.\n",
    "   - **Pre-Generated Data:** For each test case, arrays are generated once and reused during the benchmark loop to ensure consistency.\n",
    "   - **Data Type Consistency:** All arrays are explicitly converted to double precision (`np.float64`) to match the Eigen type (`double`).\n",
    "\n",
    "4. **Range of Test Sizes:**\n",
    "   - We test a wide range of sizes—from small (10×10) to large (5000×5000) matrices—to capture the performance behavior under different scales. This helps us observe how the overhead scales with problem size.\n",
    "\n",
    "## Additional Considerations for ND Operations:\n",
    "- Our current implementations focus on 1D and 2D operations (e.g., for `inner`, `outer`, `matmult`, `append`, `concat`, `rot90`).\n",
    "- For functions that inherently support n-dimensional arrays (such as `numpy.stack`), if we implement these in the future, similar principles would apply: pre-convert data if needed, ensure vectorized operations, and measure pure computation time.\n",
    "- The benchmark must isolate the computational part from any overhead due to Python binding or data conversion to produce a meaningful comparison.\n",
    "\n",
    "By following these guidelines, we ensure that our benchmark results reflect the true computational performance of the underlying algorithms rather than artifacts of the Python-C++ interface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MyPyEigen as pe\n",
    "import numpy as np\n",
    "import timeit, functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark Results for NumPy functions (Average time in seconds):\n",
      "\n",
      "Function: matmult\n",
      "Size\tAverage Time (sec)\n",
      "10\t0.000001504\n",
      "50\t0.000004983\n",
      "100\t0.000013821\n",
      "500\t0.000949358\n",
      "1000\t0.007864650\n",
      "2000\t0.063897550\n",
      "5000\t1.013861154\n",
      "\n",
      "Function: append\n",
      "Size\tAverage Time (sec)\n",
      "10\t0.000001867\n",
      "50\t0.000002612\n",
      "100\t0.000004733\n",
      "500\t0.000214204\n",
      "1000\t0.000541433\n",
      "2000\t0.004133825\n",
      "5000\t0.035949937\n",
      "\n",
      "Function: concat\n",
      "Size\tAverage Time (sec)\n",
      "10\t0.000000983\n",
      "50\t0.000001975\n",
      "100\t0.000004913\n",
      "500\t0.000366783\n",
      "1000\t0.001426362\n",
      "2000\t0.005924200\n",
      "5000\t0.053742600\n",
      "\n",
      "Function: inner\n",
      "Size\tAverage Time (sec)\n",
      "10\t0.000000445\n",
      "50\t0.000000445\n",
      "100\t0.000000454\n",
      "500\t0.000000508\n",
      "1000\t0.000000591\n",
      "2000\t0.000000737\n",
      "5000\t0.000001217\n",
      "\n",
      "Function: outer\n",
      "Size\tAverage Time (sec)\n",
      "10\t0.000001307\n",
      "50\t0.000002482\n",
      "100\t0.000021144\n",
      "500\t0.000202705\n",
      "1000\t0.000821448\n",
      "2000\t0.003679805\n",
      "5000\t0.027354049\n",
      "\n",
      "Function: rot90\n",
      "Size\tAverage Time (sec)\n",
      "10\t0.000003645\n",
      "50\t0.000003582\n",
      "100\t0.000003571\n",
      "500\t0.000003550\n",
      "1000\t0.000003642\n",
      "2000\t0.000003627\n",
      "5000\t0.000003612\n"
     ]
    }
   ],
   "source": [
    "# --- Benchmark Utility Function ---\n",
    "def benchmark_function(func, args, number=10, preheat=5):\n",
    "    \"\"\"\n",
    "    Benchmark 'func' with arguments 'args'. First, preheat the cache by calling the function\n",
    "    'preheat' times. Then, call 'func' 'number' times and return the average execution time.\n",
    "    \"\"\"\n",
    "    # Preheat to minimize cache/memory initialization overhead.\n",
    "    for _ in range(preheat):\n",
    "        func(*args)\n",
    "    return timeit.timeit(lambda: func(*args), number=number) / number\n",
    "\n",
    "# --- Ensure Reproducibility ---\n",
    "np.random.seed(12345)\n",
    "\n",
    "# --- Define Test Sizes ---\n",
    "# We extend the test sizes to larger values for a more meaningful benchmark.\n",
    "sizes = [10, 50, 100, 500, 1000, 2000, 5000]\n",
    "\n",
    "# --- Initialize a Dictionary to Hold Benchmark Results ---\n",
    "results = {}\n",
    "\n",
    "# 1. Benchmark Matrix Multiplication (matmult)\n",
    "results['matmult'] = []\n",
    "for size in sizes:\n",
    "    A = np.random.rand(size, size).astype(np.float64)\n",
    "    B = np.random.rand(size, size).astype(np.float64)\n",
    "    # Benchmark NumPy matrix multiplication using '@'\n",
    "    t_np = benchmark_function(lambda A, B: A @ B, (A, B), number=10)\n",
    "    results['matmult'].append((size, t_np))\n",
    "\n",
    "# 2. Benchmark Append (row-wise using vstack)\n",
    "results['append'] = []\n",
    "for size in sizes:\n",
    "    X = np.random.rand(size, size).astype(np.float64)\n",
    "    Y = np.random.rand(size, size).astype(np.float64)\n",
    "    t_np = benchmark_function(lambda X, Y: np.vstack((X, Y)), (X, Y), number=10)\n",
    "    results['append'].append((size, t_np))\n",
    "\n",
    "# 3. Benchmark Concat (row-wise using concatenate)\n",
    "results['concat'] = []\n",
    "for size in sizes:\n",
    "    A2 = np.random.rand(size, size).astype(np.float64)\n",
    "    B2 = np.random.rand(size, size).astype(np.float64)\n",
    "    C2 = np.random.rand(size, size).astype(np.float64)\n",
    "    t_np = benchmark_function(lambda lst: np.concatenate(lst, axis=0), ([A2, B2, C2],), number=10)\n",
    "    results['concat'].append((size, t_np))\n",
    "\n",
    "# 4. Benchmark Inner (1D vector dot product using np.inner)\n",
    "results['inner'] = []\n",
    "for size in sizes:\n",
    "    v1 = np.random.rand(size).astype(np.float64)\n",
    "    v2 = np.random.rand(size).astype(np.float64)\n",
    "    # Increase the repetition count to better average out fixed overhead.\n",
    "    t_np = benchmark_function(np.inner, (v1, v2), number=10000)\n",
    "    results['inner'].append((size, t_np))\n",
    "\n",
    "# 5. Benchmark Outer (1D vector outer product using np.outer)\n",
    "results['outer'] = []\n",
    "for size in sizes:\n",
    "    v1 = np.random.rand(size).astype(np.float64)\n",
    "    v2 = np.random.rand(size).astype(np.float64)\n",
    "    t_np = benchmark_function(np.outer, (v1, v2), number=10000)\n",
    "    results['outer'].append((size, t_np))\n",
    "\n",
    "# 6. Benchmark Rot90 (rotate 2D array using np.rot90)\n",
    "results['rot90'] = []\n",
    "for size in sizes:\n",
    "    M = np.random.rand(size, size).astype(np.float64)\n",
    "    t_np = benchmark_function(lambda M: np.rot90(M, 1), (M,), number=100)\n",
    "    results['rot90'].append((size, t_np))\n",
    "\n",
    "# --- Print Benchmark Results ---\n",
    "print(\"Benchmark Results for NumPy functions (Average time in seconds):\")\n",
    "for func_name, data in results.items():\n",
    "    print(f\"\\nFunction: {func_name}\")\n",
    "    print(\"Size\\tAverage Time (sec)\")\n",
    "    for size, t in data:\n",
    "        print(f\"{size}\\t{t:.9f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Considerations for MyPyEigen vs. NumPy\n",
    "\n",
    "## Overview\n",
    "This benchmark measures the performance of our custom Eigen-based functions (exposed via MyPyEigen) in Python, including:\n",
    "- **matmult**: Matrix multiplication (similar to `numpy.matmul` or `@`)\n",
    "- **append**: Appending two matrices along a given axis (similar to `numpy.append`/`vstack` or `hstack`)\n",
    "- **concat**: Concatenating multiple matrices (similar to `numpy.concatenate`)\n",
    "- **inner**: 1D vector inner product (similar to `numpy.inner` or `np.dot` for vectors)\n",
    "- **outer**: 1D vector outer product (similar to `numpy.outer`)\n",
    "- **rot90**: Rotating a matrix by 90 degrees (similar to `numpy.rot90`)\n",
    "\n",
    "## Key Considerations for a Fair Benchmark\n",
    "1. **Preheating/Caching:**  \n",
    "   To minimize one-time initialization or cache-warmup overhead, we preheat the function calls (i.e., run them several times before timing).\n",
    "\n",
    "2. **Reproducibility:**  \n",
    "   We fix the random seed (e.g., `np.random.seed(12345)`) to ensure that test cases are consistent across runs.\n",
    "\n",
    "3. **Data Preprocessing Exclusion:**  \n",
    "   We generate the test arrays before timing so that data creation and conversion overheads are not included in the benchmark.\n",
    "\n",
    "4. **Range of Test Sizes:**  \n",
    "   We test across a range of sizes (from 10x10 to 5000x5000) to observe how performance scales with problem size.\n",
    "\n",
    "5. **Data Type Consistency:**  \n",
    "   All arrays are generated with `np.float64` (i.e., 64-bit double) to ensure fair comparison with Eigen's double-based computations.\n",
    "\n",
    "## Note on Python Binding Overhead\n",
    "While pybind11 automatically converts NumPy arrays to Eigen types and vice versa, the overhead from these conversions is generally small. However, for very small arrays, this overhead might be significant relative to the computation. In our benchmarks, we call each function many times to amortize the fixed cost.\n",
    "\n",
    "The goal is to compare the pure computational performance as fairly as possible between our Eigen-based implementation and NumPy's native operations.\n",
    "\n",
    "---\n",
    "\n",
    "By following these guidelines, we aim to ensure that our benchmarks reflect the true performance of the underlying linear algebra computations.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "Benchmark Results for NumPy functions (Average time in seconds):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Function: matmult**  \n",
    "\n",
    "| Size | NumPy Time (sec) | MyPyEigen Time (sec) | Speedup Factor |\n",
    "|------|------------------|----------------------|----------------|\n",
    "| 10   | 0.000001504      | 0.000002179          | 0.69x (Slower) |\n",
    "| 50   | 0.000004983      | 0.000013704          | 0.36x (Slower) |\n",
    "| 100  | 0.000013821      | 0.000079625          | 0.17x (Slower) |\n",
    "| 500  | 0.000949358      | 0.006776463          | 0.14x (Slower) |\n",
    "| 1000 | 0.007864650      | 0.050868921          | 0.15x (Slower) |\n",
    "| 2000 | 0.063897550      | 0.385726825          | 0.17x (Slower) |\n",
    "| 5000 | 1.013861154      | 6.352387050          | 0.16x (Slower) |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- **Function: append**  \n",
    "\n",
    "| Size | NumPy Time (sec) | MyPyEigen Time (sec) | Speedup Factor     |\n",
    "|------|------------------|----------------------|--------------------|\n",
    "| 10   | 0.000001867      | 0.000001904          | ~1.02x (Similar)   |\n",
    "| 50   | 0.000002612      | 0.000015279          | 0.17x (Slower)     |\n",
    "| 100  | 0.000004733      | 0.000036296          | 0.13x (Slower)     |\n",
    "| 500  | 0.000214204      | 0.001396075          | 0.15x (Slower)     |\n",
    "| 1000 | 0.000541433      | 0.006081629          | 0.09x (Slower)     |\n",
    "| 2000 | 0.004133825      | 0.032367979          | 0.13x (Slower)     |\n",
    "| 5000 | 0.035949937      | 0.426710392          | 0.08x (Slower)     |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Function: concat** \n",
    "\n",
    "| Size | NumPy Time (sec) | MyPyEigen Time (sec) | Speedup Factor |\n",
    "|------|------------------|----------------------|----------------|\n",
    "| 10   | 0.000000983      | 0.000002267          | 0.43x (Slower) |\n",
    "| 50   | 0.000001975      | 0.000026642          | 0.07x (Slower) |\n",
    "| 100  | 0.000004913      | 0.000062163          | 0.08x (Slower) |\n",
    "| 500  | 0.000366783      | 0.002711667          | 0.14x (Slower) |\n",
    "| 1000 | 0.001426362      | 0.010954300          | 0.13x (Slower) |\n",
    "| 2000 | 0.005924200      | 0.050432475          | 0.12x (Slower) |\n",
    "| 5000 | 0.053742600      | 0.642031071          | 0.08x (Slower) |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Function: inner**  \n",
    "\n",
    "| Size | NumPy Time (sec) | MyPyEigen Time (sec) | Speedup Factor     |\n",
    "|------|------------------|----------------------|--------------------|\n",
    "| 10   | 0.000000445      | 0.000000979          | 0.45x (Slower)     |\n",
    "| 50   | 0.000000445      | 0.000000951          | 0.47x (Slower)     |\n",
    "| 100  | 0.000000454      | 0.000000965          | 0.47x (Slower)     |\n",
    "| 500  | 0.000000508      | 0.000001054          | 0.48x (Slower)     |\n",
    "| 1000 | 0.000000591      | 0.000001260          | 0.47x (Slower)     |\n",
    "| 2000 | 0.000000737      | 0.000001602          | 0.46x (Slower)     |\n",
    "| 5000 | 0.000001217      | 0.000023336          | 0.05x (Slower)     |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Function: outer**  \n",
    "\n",
    "| Size | NumPy Time (sec) | MyPyEigen Time (sec) | Speedup Factor |\n",
    "|------|------------------|----------------------|----------------|\n",
    "| 10   | 0.000001307      | 0.000001398          | 0.93x (Similar)|\n",
    "| 50   | 0.000002482      | 0.000002877          | 0.86x (Slower) |\n",
    "| 100  | 0.000021144      | 0.000018673          | 1.13x (Faster) |\n",
    "| 500  | 0.000202705      | 0.000358850          | 0.56x (Slower) |\n",
    "| 1000 | 0.000821448      | 0.001814471          | 0.45x (Slower) |\n",
    "| 2000 | 0.003679805      | 0.009134711          | 0.40x (Slower) |\n",
    "| 5000 | 0.027354049      | 0.109140976          | 0.25x (Slower) |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Function: rot90**  \n",
    "\n",
    "| Size | NumPy Time (sec) | MyPyEigen Time (sec) | Speedup Factor |\n",
    "|------|------------------|----------------------|----------------|\n",
    "| 10   | 0.000003645      | 0.000001235          | 2.95x (Faster) |\n",
    "| 50   | 0.000003582      | 0.000004167          | 0.86x (Slower) |\n",
    "| 100  | 0.000003571      | 0.000033881          | 0.11x (Slower) |\n",
    "| 500  | 0.000003550      | 0.000884480          | 0.004x (Slower)|\n",
    "| 1000 | 0.000003642      | 0.005710024          | 0.0006x (Slower)|\n",
    "| 2000 | 0.000003627      | 0.024798107          | 0.0001x (Slower)|\n",
    "| 5000 | 0.000003612      | 0.328406906          | 0.00001x (Slower)|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
